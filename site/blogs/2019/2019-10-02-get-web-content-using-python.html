<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8 no-js"> <![endif]-->
<!--[if IE 9]> <html lang="en" class="ie9 no-js"> <![endif]-->
<!--[if !IE]><!--> <html lang="zh" class="no-js"> <!--<![endif]-->
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="../../../css/bootstrap.min-2.3.1.css">
	<link rel="stylesheet" type="text/css" href="../../../css/bootstrap-responsive.min.css">
	<link rel="stylesheet" type="text/css" href="../../../css/bootstrap-style.css">
    <link rel="stylesheet" type="text/css" href="../../../css/font-awesome.min.css">
	<link rel="stylesheet" type="text/css" href="../../../css/menu.css">
	<link rel="stylesheet" type="text/css" href="../../../css/blog.css">
    <link rel="stylesheet" type="text/css" href="../../../css/style.css">
	<link rel='stylesheet' type='text/css' href='../../../css/shCoreRDark.css'/>
	<link rel="shortcut icon" href="../../../img/logo.ico" />
    <title>GaoHR | Python网页爬虫IP被限制的解决方法</title>
	<style>
		
	</style>
</head>

<body>
	<!--head-->
	<div class="mainlogo">
		<a href="../../../index.html"><span class="g-left">G</span>aoHR</a>
		<img src="../../../img/head.png" class="headimg">
		<p><img src="../../../img/welcome.png" class="welcome"></p>
		<script src="http://pv.sohu.com/cityjson?ie=utf-8"></script>
		<div class="weather" id ="weather"></div>
	</div>
	<div class="container-fluid main-page">
		<div class="row-fluid">
			<div class="span2">
				<!--responsive menu-->
				<div id="mainmenu"></div>
			</div>
			<div class="span8">
				<!--breadcrumb-->
				<ol class="breadcrumb">
					<li><a href="../../../index.html"><i class="icon-home"></i> Home</a></li>
					<i class="icon-angle-right"></i>
					<a href="../../../Blogs.html"> Blog</a>
					<!--<li class="active">Blog</li>-->
				</ol>
				<!--正文-->
				<input id="blogid" style="display:none" value="2019100201">
				<div class="blogcontent alist">
					<h2>Python网络爬虫IP被限制的解决方法</h2>
					<h2><small>Solutions to IP Restriction in Web Page Crawling with Python</small></h2>
					<div class="blogtopinfo"><span id="blogtopinfo"></span></div>
					<p>网络爬虫是用于数据采集的一门技术，可以自动高效地进行信息的获取与筛选。从技术手段来说，网络爬虫有多种实现方案，如Python、Java、...。使用Python也会有很多不同的技术方案（urllib、requests、...)，每种技术各有各的特点，只需掌握一种技术，其它便迎刃而解。</p>
					<p>但是，网络爬虫的难点并不在于网络爬虫本身，而在于网页的分析与爬虫的反爬攻克问题。高强度、高频率地爬取网页信息常常会给网站的服务器带来巨大压力，因此在利用Python进行网页爬虫的时候，经常会遇到所要爬取的网站采取了反爬虫技术，同一个IP反复爬取一个网站，就很可能被限制IP，无法访问该网站。</p>
					<p class="g-color-red">本文不再具体介绍Python爬虫和网页分析的技术，网上教程资源很多，主要介绍在使用Python爬虫时遇到的IP被限制的问题，及其简单有效的解决方法。</p>
					<p class="blog-sub-title"><b>反爬虫示例</b></p>
					<p>以某房产网站为例，爬虫抓取网站内容时会出现以下错误页面，导致爬虫无法继续抓取原始页面数据。</p>
					<p class="imginblog"><img src="2019-10-02-get-web-content-using-python\img001.jpg"></p>
					<p class="blog-sub-title"><b>常用的解决方法</b></p>
					<p><b>1. 模拟浏览器访问</b></p>
					<p>网上经常会看到有些爬虫代码会设置<code>headers</code>变量，这是用来模拟浏览器上网用的，因为有些网站设置的反爬虫机制，需要使用浏览器上网才可以访问。</p>
					<p><code>headers</code>的设置也非常简单。</p>
					<p>首先，打开调试面板，找到自己浏览器发送请求时的<code>headers</code>，其中，<code>User-agent</code>是用来表示请求者的信息，可以搜集<code>User-agent</code>并保存，爬取过程中动态更换在<code>User-agent</code>，伪装成浏览器的形式。如下图所示。</p>
					<p class="imginblog"><img src="2019-10-02-get-web-content-using-python\img002.jpg"></p>
					<p>然后，在爬虫代码中加入<code>headers</code>变量</p>
					<div id="highlighter_796187" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">import</code>&nbsp;<code class="python plain">requests</code></div><div class="line number2 index1 alt1"><code class="python plain">url&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python string">"&lt;url&gt;"</code></div><div class="line number3 index2 alt2"><code class="python plain">headers&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">{</code><code class="python string">'User-Agent'</code><code class="python plain">:&nbsp;</code><code class="python string">'Mozilla/5.0&nbsp;(Windows&nbsp;NT&nbsp;6.3;&nbsp;WOW64)&nbsp;AppleWebKit/537.36&nbsp;(KHTML,&nbsp;like&nbsp;Gecko)&nbsp;Chrome/55.0.2883.87&nbsp;Safari/537.36'</code><code class="python plain">}</code></div><div class="line number4 index3 alt1"><code class="python plain">web_data&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">requests.get(url,&nbsp;headers</code><code class="python keyword">=</code><code class="python plain">headers)</code></div></div></td></tr></tbody></table></div>
					<p>这样就能成功的爬取到部分网站的网页信息了。</p>
					<p><b>2. 设置动态IP代理</b></p>
					<p>通过设置模拟浏览器代理来访问获取页面内容，始终只有一个IP地址用来访问,用的多了同样也会被某些网站封掉。</p>
					<p class="g-color-red">所以设置动态IP代理进行访问成为一种反爬虫的更好策略，即通过其他的IP代替自己的IP进行网站访问。</p>
					<p>免费的代理IP网站有很多，虽然这种网站都不会提供太多的代理IP，但足够我们使用了。本文以西刺代理的免费IP代理网站（<a href="www.xicidaili.com/nn/" target="_blank">www.xicidaili.com/nn/</a>）为例，介绍一下在python中如何使用动态IP代理。</p>
					<p>打开网站，可以看到这里有很多代理IP列表，总共超过30万条代理IP地址。</p>
					<p class="imginblog"><img src="2019-10-02-get-web-content-using-python\img003.jpg"></p>
					<p>设置IP代理需要修改<code>proxies</code>变量，<code>proxies</code>变量的格式是一个字典：{'http': 'http://xx.xx.xx.xx:xxxx'}，需要注意的是，<code>proxises</code>有http与https两种，在爬取不同网站时我们需要选用不同类型的网站时选用不同的<code>proxise</code>。</p>
					<div id="highlighter_908520" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python comments">#&nbsp;http型：</code></div><div class="line number2 index1 alt1"><code class="python plain">{</code><code class="python string">'http'</code><code class="python plain">:&nbsp;</code><code class="python string">'<a href="http://xx.xx.xx.xx:xxxx">http://xx.xx.xx.xx:xxxx</a>'</code><code class="python plain">}</code></div><div class="line number3 index2 alt2"><code class="python comments">#&nbsp;https型：</code></div><div class="line number4 index3 alt1"><code class="python plain">{</code><code class="python string">'https'</code><code class="python plain">:&nbsp;</code><code class="python string">'<a href="http://xx.xx.xx.xx:xxxx">http://xx.xx.xx.xx:xxxx</a>'</code><code class="python plain">}</code></div></div></td></tr></tbody></table></div>
					<p>然后，从代理IP列表随机抓取IP地址，组成<code>proxies</code>，代码如下。</p>
					<div id="highlighter_200543" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div><div class="line number16 index15 alt1">16</div><div class="line number17 index16 alt2">17</div><div class="line number18 index17 alt1">18</div><div class="line number19 index18 alt2">19</div><div class="line number20 index19 alt1">20</div><div class="line number21 index20 alt2">21</div><div class="line number22 index21 alt1">22</div><div class="line number23 index22 alt2">23</div><div class="line number24 index23 alt1">24</div><div class="line number25 index24 alt2">25</div><div class="line number26 index25 alt1">26</div><div class="line number27 index26 alt2">27</div><div class="line number28 index27 alt1">28</div><div class="line number29 index28 alt2">29</div><div class="line number30 index29 alt1">30</div><div class="line number31 index30 alt2">31</div><div class="line number32 index31 alt1">32</div><div class="line number33 index32 alt2">33</div><div class="line number34 index33 alt1">34</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">import</code>&nbsp;<code class="python plain">requests</code></div><div class="line number2 index1 alt1"><code class="python keyword">import</code>&nbsp;<code class="python plain">random</code></div><div class="line number3 index2 alt2"><code class="python keyword">from</code>&nbsp;<code class="python plain">bs4&nbsp;</code><code class="python keyword">import</code>&nbsp;<code class="python plain">BeautifulSoup</code></div><div class="line number4 index3 alt1">&nbsp;</div><div class="line number5 index4 alt2"><code class="python keyword">def</code>&nbsp;<code class="python plain">get_ip_list(url,&nbsp;headers):</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">web_data&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">requests.get(url,&nbsp;headers</code><code class="python keyword">=</code><code class="python plain">headers)</code></div><div class="line number7 index6 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">soup&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">BeautifulSoup(web_data.text,&nbsp;</code><code class="python string">'html.parser'</code><code class="python plain">)</code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">ips&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">soup.find_all(</code><code class="python string">'tr'</code><code class="python plain">)</code></div><div class="line number9 index8 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">ip_list&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">[]</code></div><div class="line number10 index9 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">for</code>&nbsp;<code class="python plain">i&nbsp;</code><code class="python keyword">in</code>&nbsp;<code class="python functions">range</code><code class="python plain">(</code><code class="python value">1</code><code class="python plain">,&nbsp;</code><code class="python functions">len</code><code class="python plain">(ips)):</code></div><div class="line number11 index10 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">ip_info&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">ips[i]</code></div><div class="line number12 index11 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">tds&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">ip_info.find_all(</code><code class="python string">'td'</code><code class="python plain">)</code></div><div class="line number13 index12 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">ip_list.append(tds[</code><code class="python value">1</code><code class="python plain">].text&nbsp;</code><code class="python keyword">+</code>&nbsp;<code class="python string">':'</code>&nbsp;<code class="python keyword">+</code>&nbsp;<code class="python plain">tds[</code><code class="python value">2</code><code class="python plain">].text)</code></div><div class="line number14 index13 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">return</code>&nbsp;<code class="python plain">ip_list</code></div><div class="line number15 index14 alt2">&nbsp;</div><div class="line number16 index15 alt1">&nbsp;</div><div class="line number17 index16 alt2"><code class="python keyword">def</code>&nbsp;<code class="python plain">get_random_ip(ip_list):</code></div><div class="line number18 index17 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">proxy_list&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">[]</code></div><div class="line number19 index18 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">for</code>&nbsp;<code class="python plain">ip&nbsp;</code><code class="python keyword">in</code>&nbsp;<code class="python plain">ip_list:</code></div><div class="line number20 index19 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">proxy_list.append(</code><code class="python string">'<a href="http://">http://</a>'</code>&nbsp;<code class="python keyword">+</code>&nbsp;<code class="python plain">ip)</code></div><div class="line number21 index20 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">proxy_ip&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">random.choice(proxy_list)</code></div><div class="line number22 index21 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments">#&nbsp;注意此处修改http或https</code></div><div class="line number23 index22 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">proxies&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">{</code><code class="python string">'http'</code><code class="python plain">:&nbsp;proxy_ip}</code></div><div class="line number24 index23 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">return</code>&nbsp;<code class="python plain">proxies</code></div><div class="line number25 index24 alt2">&nbsp;</div><div class="line number26 index25 alt1"><code class="python comments">#&nbsp;main</code></div><div class="line number27 index26 alt2"><code class="python plain">url&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python string">'<a href="http://www.xicidaili.com/nn/">http://www.xicidaili.com/nn/</a>'</code></div><div class="line number28 index27 alt1"><code class="python plain">headers&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">{</code></div><div class="line number29 index28 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python string">'User-Agent'</code><code class="python plain">:&nbsp;</code><code class="python string">'Mozilla/5.0&nbsp;(Windows&nbsp;NT&nbsp;10.0;&nbsp;Win64;&nbsp;x64)&nbsp;AppleWebKit/537.36&nbsp;(KHTML,&nbsp;like&nbsp;Gecko)&nbsp;Chrome/75.0.3770.100&nbsp;Safari/537.36'</code></div><div class="line number30 index29 alt1"><code class="python plain">}</code></div><div class="line number31 index30 alt2"><code class="python plain">ip_list&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">get_ip_list(url,&nbsp;headers</code><code class="python keyword">=</code><code class="python plain">headers)</code></div><div class="line number32 index31 alt1"><code class="python plain">proxies&nbsp;</code><code class="python keyword">=</code>&nbsp;<code class="python plain">get_random_ip(ip_list)</code></div><div class="line number33 index32 alt2">&nbsp;</div><div class="line number34 index33 alt1"><code class="python plain">requests.get(url,&nbsp;headers</code><code class="python keyword">=</code><code class="python plain">headers,&nbsp;proxies</code><code class="python keyword">=</code><code class="python plain">proxies)</code></div></div></td></tr></tbody></table></div>
					<p>这样，就可以在<code>requests.get()</code>函数中添加<code>proxies</code>参数，设置代理IP。</p>
					<p>通过将获取代理IP的代码放置到合适的位置，实现实时动态的IP代理更新，每次抓取页面都可以获取新的IP，达到防止IP被限制的目的。</p>
					<p></p>
					<hr>
					<br>
					<p>Fighting, GISer!</p>
					<!-- Warning -->
					<div id="warning"></div>
				</div>
				<!-- Da shang -->
				<div id="dashang" class="dashang"></div>
				<!-- Comments -->
				<div id="comments"></div>
			</div>
			<div class="span2">
				<div class="block"></div>
				<div class="portlet" id="declareDiv"></div>
				<div class="block"></div>
				<div class="portlet">
					<p class="title"><i class="icon-book"></i><b>最新博文</b></p>
					<br>
					<div class="blog-page" id="blogs"></div>
				</div>
				<!-- Share -->
				<div id="shareit"></div>
			</div>
		</div>
	</div>
	<!-- others  --> 
	<div id="others"></div>
	<!-- footer  --> 
	<footer>
		<p id="copyright" class="copyright"></p>
	</footer>
    <!-- JavaScript -->
    <script src="../../../js/jquery.min.js"></script>
    <script src="../../../js/bootstrap.min.js"></script>
	<script src="../../../js/echarts.min.js"></script>
	<script src="../../../js/bloglist.js"></script>
	<script src="../../special/js/topicslist.js"></script>
	<script src="../../../js/paylist.js"></script>
	<script src="../blogsload.js"></script>
	<script src="../../../js/common.js"></script>
</body>
</html>
